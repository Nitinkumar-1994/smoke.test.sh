*******************Setup for Confluent Kafka RHEL 8 ( Kafka Server , Producer & Consumer)*****************************************


===========================Overview=====================================

- **Kafka Server Machine**:
  - Public IP: `13.201.176.17`
  - Private IP: `172.31.26.244`
  - Runs ZooKeeper, Kafka broker, and Confluent Control Center.
- **Producer Machine**:
  - Public IP: `13.202.43.206`
  - Private IP: `172.31.28.235`
  - Runs Kafka client to produce messages.
- **Consumer Machine**:
  - Public IP: `13.234.12.41`
  - Private IP: `172.31.21.26`
  - Runs Kafka client to consume messages.
- **Assumptions**:
  - All machines are RHEL 8 EC2 instances (AMI: `ami-0619404f9180a28b3`, C5.large, 30 GB EBS).
  - Security groups are configured:
    - Kafka Server: Allow inbound TCP on 22 (SSH), 2181 (ZooKeeper), 9092 (Kafka), 9021 (Control Center) from your IP and producer/consumer IPs.
    - Producer/Consumer: Allow inbound TCP on 22 (SSH) from your IP.


=======================Step 2: Set Up the Kafka Server Machine==============================

SSH into the Kafka Server

ssh -i your-key.pem ec2-user@public-ip                   #Replace your-key.pem with your SSH key file

=================**All host access shell script like dsh**=============

Send pem key to the main host using pscp or scp

scp -i cloudera.pem cloudera.pem ec2-user@ipaddress:/home/ec2-user                   #Send Same SSH key (`your-key.pem`) for all instances

chmod 400 cloudera.pem

sudo vi cluster                    # Put all ip in clutser file (from ec2 istances)

sudo vi clustercmd.sh         #Auto for all the machines

for i in `cat cluster`; do
ssh -t -i ./cloudera.pem ec2-user@$i $*       #change the keyname(cloudage.pem)
done

:wq! 


sh clustercmd.sh uptime --pretty

sh clustercmd.sh sudo yum update -y                      #Update all 3 nodes 

sh clustercmd.sh sudo yum install -y wget tar nano firewalld java-11-openjdk java-11-openjdk-devel       #download this in all 3 nodes

==================Essential kernel tuning parameters=============================

$ vi kafka_kernel_tuning.sh

+++start from Paste below all lines 

#!/bin/bash

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo "This script must be run as root. Use sudo." >&2
    exit 1
fi

# ===== KERNEL PARAMETERS =====
echo "Applying kernel tuning for Kafka..."

# Network & Socket Buffers
cat >> /etc/sysctl.conf <<EOF
# Kafka Network Tuning
net.core.rmem_max=16777216
net.core.wmem_max=16777216
net.ipv4.tcp_rmem=4096 87380 16777216
net.ipv4.tcp_wmem=4096 65536 16777216
net.ipv4.tcp_no_metrics_save=1
net.ipv4.tcp_sack=0
net.ipv4.tcp_timestamps=0

# File Descriptors & Processes
fs.file-max=1000000
fs.nr_open=1000000
kernel.pid_max=262144

# Virtual Memory
vm.swappiness=1
vm.dirty_background_ratio=5
vm.dirty_ratio=60
vm.dirty_expire_centisecs=2000
EOF

# Apply sysctl changes
sysctl -p

# ===== DISABLE TRANSPARENT HUGEPAGES =====
echo "Disabling Transparent HugePages (THP)..."
echo never > /sys/kernel/mm/transparent_hugepage/enabled
echo never > /sys/kernel/mm/transparent_hugepage/defrag

# Make THP settings persistent
if ! grep -q "transparent_hugepage" /etc/rc.local; then
    echo "echo never > /sys/kernel/mm/transparent_hugepage/enabled" >> /etc/rc.local
    echo "echo never > /sys/kernel/mm/transparent_hugepage/defrag" >> /etc/rc.local
    chmod +x /etc/rc.local
fi

# ===== DISK I/O SCHEDULER =====
# Set deadline/noop scheduler for all disks (prioritize Kafka I/O)
for disk in $(lsblk -d -o NAME | grep -v NAME); do
    if [ -e /sys/block/$disk/queue/scheduler ]; then
        echo "Setting deadline scheduler for $disk..."
        echo deadline > /sys/block/$disk/queue/scheduler
        echo 1024 > /sys/block/$disk/queue/nr_requests
    fi
done

# ===== ULIMITS FOR KAFKA USER =====
KAFKA_USER="kafka"  # Change to your Kafka user if different

if id "$KAFKA_USER" &>/dev/null; then
    echo "Increasing ulimits for user $KAFKA_USER..."
    cat >> /etc/security/limits.conf <<EOF
$KAFKA_USER soft nofile 1000000
$KAFKA_USER hard nofile 1000000
$KAFKA_USER soft nproc 65536
$KAFKA_USER hard nproc 65536
EOF
else
    echo "Warning: User '$KAFKA_USER' not found. Skipping ulimit changes."
fi

# ===== VERIFY CHANGES =====
echo ""
echo "=== Verification ==="
echo "Network buffers:"
sysctl net.core.rmem_max net.core.wmem_max

echo ""
echo "THP status:"
cat /sys/kernel/mm/transparent_hugepage/enabled

echo ""
echo "Disk schedulers:"
for disk in $(lsblk -d -o NAME | grep -v NAME); do
    if [ -e /sys/block/$disk/queue/scheduler ]; then
        echo "$disk: $(cat /sys/block/$disk/queue/scheduler)"
    fi
done

echo ""
echo "Script completed. Reboot to ensure all changes take effect."

+++++Till Here 


$ chmod +x kafka_kernel_tuning.sh

$ sudo ./kafka_kernel_tuning.sh


NOTE - Do this kernel Tuning on all machine 

===================Download and Extract Confluent===============================================

sh clustercmd.sh sudo wget -c https://packages.confluent.io/archive/5.5/confluent-5.5.0-2.12.tar.gz              #Download repo of confluent kafka

or

https://packages.confluent.io/archive/7.4/confluent-7.4.1.tar.gz              # Refer from https://packages.confluent.io/archive/

sh clustercmd.sh sudo tar -xzvf confluent-5.5.0-2.12.tar.gz

sh clustercmd.sh sudo mv confluent-5.5.0 /opt/confluent

sh clustercmd.sh sudo chown -R ec2-user:ec2-user /opt/confluent


====================Set Environment Variables on 3 machine login one & one ==========================================

echo 'export PATH=$PATH:/opt/confluent/bin' >> ~/.bashrc

echo 'export JAVA_HOME=/usr/lib/jvm/java-11-openjdk' >> ~/.bashrc

source ~/.bashrc

echo $PATH

-----------SSH into the Producer Server-----------

ssh -i your-key.pem ec2-user@public-ip 

echo 'export PATH=$PATH:/opt/confluent/bin' >> ~/.bashrc

echo 'export JAVA_HOME=/usr/lib/jvm/java-11-openjdk' >> ~/.bashrc

source ~/.bashrc

echo $PATH

-----------SSH into the Consumer Server-----------

ssh -i your-key.pem ec2-user@public-ip 

echo 'export PATH=$PATH:/opt/confluent/bin' >> ~/.bashrc

echo 'export JAVA_HOME=/usr/lib/jvm/java-11-openjdk' >> ~/.bashrc

source ~/.bashrc

echo $PATH

===============Configure ZooKeeper=========================

sudo mkdir -p /var/lib/zookeeper

sudo chown ec2-user:ec2-user /var/lib/zookeeper

sudo vi /opt/confluent/etc/kafka/zookeeper.properties

  dataDir=/var/lib/zookeeper
  clientPort=2181
  maxClientCnxns=0
  tickTime=2000
  initLimit=5
  syncLimit=2


++++++++++Configure Kafka+++++++++

sudo mkdir -p /var/lib/kafka

sudo chown ec2-user:ec2-user /var/lib/kafka


++++++++Edit configuration++++++++

sudo vi /opt/confluent/etc/kafka/server.properties

   broker.id=0
   listeners=PLAINTEXT://0.0.0.0:9092
   advertised.listeners=PLAINTEXT://13.202.73.202:9092            # Uses public IP Kafka Server Machine
   zookeeper.connect=172.31.17.172:2181                                   # Uses private IP Kafka Server Machine
   log.dirs=/var/lib/kafka
   num.partitions=1
   default.replication.factor=1
   offsets.topic.replication.factor=1
   transaction.state.log.replication.factor=1
   transaction.state.log.min.isr=1


============Configure Confluent Control Center==========

sudo mkdir -p /var/lib/confluent-control-center

sudo chown ec2-user:ec2-user /var/lib/confluent-control-center


++++++++Edit configuration+++++++++

sudo vi /opt/confluent/etc/confluent-control-center/control-center.properties

 
   confluent.controlcenter.data.dir=/var/lib/confluent-control-center
   confluent.controlcenter.rest.listeners=http://0.0.0.0:9021
   bootstrap.servers=13.202.73.202:9092                                                # Uses public IP Kafka Server Machine
   zookeeper.connect=172.31.17.172:2181                                               # Uses private IP Kafka Server Machine
   confluent.controlcenter.streams.num.stream.threads=2
   confluent.controlcenter.internal.topics.replication=1
   confluent.controlcenter.command.topic.replication=1
   confluent.monitoring.interceptor.topic.replication=1
   confluent.metrics.topic.replication=1


++++++++++Configure Firewall+++++++++

sudo systemctl status firewalld

sudo systemctl start firewalld

sudo firewall-cmd --permanent --add-port=2181/tcp

sudo firewall-cmd --permanent --add-port=9092/tcp

sudo firewall-cmd --permanent --add-port=9021/tcp

sudo firewall-cmd --reload

sudo firewall-cmd --list-ports


=====================Start Services=============================

+++Start ZooKeeper++++

/opt/confluent/bin/zookeeper-server-start /opt/confluent/etc/kafka/zookeeper.properties &

ss -tuln | grep 2181

++++Start Kafka++++

/opt/confluent/bin/kafka-server-start /opt/confluent/etc/kafka/server.properties &

ss -tuln | grep 9092

+++++Start Control Center+++++

/opt/confluent/bin/control-center-start /opt/confluent/etc/confluent-control-center/control-center.properties &

ss -tuln | grep 9021


++++++++++++++++++++++++Create a Test Topic+++++++++++++++++++++++++++++++++

/opt/confluent/bin/kafka-topics --create --topic test-topic --partitions 1 --replication-factor 1 --bootstrap-server 13.202.73.202:9092              #Uses public-IP Kafka server


/opt/confluent/bin/kafka-topics --list --bootstrap-server 13.202.73.202:9092            # List down test topic



==================================****Step 3: Set Up the Producer Machine****===================================================

+++++++++SSH into the Producer machine ec2 login +++++++++++

ssh -i your-key.pem ec2-user@public-ip

++++++++++Test Producer+++++++++

***Produce messages****

/opt/confluent/bin/kafka-console-producer --topic test-topic --bootstrap-server 13.202.73.202:9092                       #Uses public-IP Kafka server


####Type messages, e.g######

   ```
   Hello, Kafka!
   Test from Producer.
   Message 1.
   ```
Press `Ctrl+C` to exit


=====================****Step 4: Set Up the Consumer Machine*****===============================

+++++++++SSH into the Consumer machine ec2 login +++++++++++

ssh -i your-key.pem ec2-user@public-ip


++++++Test Consumer+++++++++

/opt/confluent/bin/kafka-console-consumer --topic test-topic --from-beginning --bootstrap-server 13.202.73.202:9092                #Uses public-IP Kafka server


------------Expected output-----------------

```
   Hello, Kafka!
   Test from Producer.
   Message 1.
   ```

Press `Ctrl+C` to exit


===========================*****Step 5: Verify the Setup*****===========================================

+++++++++Login on Kafka Server +++++++++++

ss -tuln | grep -E '2181|9092|9021'

++++++List topics+++++++

/opt/confluent/bin/kafka-topics --list --bootstrap-server 13.202.73.202:9092                #Uses public-IP Kafka server


+++++++++Login on Consumer Server +++++++++++

   - Run producer again, send new messages


================================**Control Center**===================================

   - Open browser: `http://13.202.73.202:9021`

   - Check **Topics > test-topic** for messages.

   - Verify **Brokers** shows broker ID 0.
















































